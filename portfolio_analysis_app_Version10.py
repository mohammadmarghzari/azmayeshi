import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
import yfinance as yf
import scipy.optimize as sco

# ------------------ Utils -------------------
def get_price_dataframe_from_yf(data, ticker):
    try:
        if isinstance(data.columns, pd.MultiIndex):
            price_series = data[ticker]['Close']
        else:
            price_series = data['Close']
        df = price_series.reset_index()
        df.columns = ['Date', 'Price']
        return df, None
    except Exception as e:
        return None, f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ {ticker}: {e}"

def read_csv_file(file):
    try:
        df = pd.read_csv(file)
        df.columns = df.columns.str.strip().str.lower().str.replace('%', '')
        df.rename(columns={'date': 'Date', 'price': 'Price'}, inplace=True)
        if 'Date' not in df.columns or 'Price' not in df.columns:
            return None, "ÙØ§ÛŒÙ„ Ø¨Ø§ÛŒØ¯ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ 'Date' Ùˆ 'Price' Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯."
        return df, None
    except Exception as e:
        return None, f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ {file.name}: {e}"

def validate_weights(min_weights, max_weights, asset_names):
    min_total = np.sum([min_weights.get(name, 0)/100 for name in asset_names])
    max_total = np.sum([max_weights.get(name, 100)/100 for name in asset_names])
    if min_total > 1.0:
        return False, "ğŸ’¡ Ù…Ø¬Ù…ÙˆØ¹ Ø­Ø¯Ø§Ù‚Ù„ ÙˆØ²Ù† Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ Ø¨ÛŒØ´ØªØ± Ø§Ø² Û±Û°Û°Ùª Ø§Ø³Øª!"
    if max_total < 0.99:
        return False, "ğŸ’¡ Ù…Ø¬Ù…ÙˆØ¹ Ø­Ø¯Ø§Ú©Ø«Ø± ÙˆØ²Ù† Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ Ú©Ù…ØªØ± Ø§Ø² Û±Û°Û°Ùª Ø§Ø³Øª! Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ Ø®Ø·Ø§ Ù…Ù†ØªÙ‡ÛŒ Ø´ÙˆØ¯."
    return True, ""

def is_all_assets_valid(all_assets):
    valid_names = [
        name for name, df in all_assets
        if df is not None
        and 'Date' in df.columns
        and 'Price' in df.columns
        and (~df['Price'].isna()).sum() > 0
    ]
    return len(valid_names) > 0

def msg(msg, level="warning"):
    if level == "warning":
        st.warning(msg)
    elif level == "error":
        st.error(msg)
    elif level == "info":
        st.info(msg)
    else:
        st.success(msg)

def compact_pie_weights(asset_names, weights, min_percent=0.1):
    weights_percent = 100 * np.array(weights)
    shown_assets, shown_weights = [], []
    other_weight = 0
    for name, w in zip(asset_names, weights_percent):
        if w >= min_percent:
            shown_assets.append(name)
            shown_weights.append(w)
        else:
            other_weight += w
    if other_weight > 0:
        shown_assets.append('Ø³Ø§ÛŒØ±')
        shown_weights.append(other_weight)
    return shown_assets, shown_weights

def opt_min_variance(mean_returns, cov_matrix, bounds):
    n = len(mean_returns)
    cons = ({'type': 'eq', 'fun': lambda x: np.sum(x)-1})
    init_guess = np.ones(n)/n
    result = sco.minimize(
        lambda w: np.dot(w.T, np.dot(cov_matrix, w)),
        init_guess,
        method='SLSQP',
        bounds=bounds,
        constraints=cons
    )
    return result.x if result.success else None

def opt_max_sharpe(mean_returns, cov_matrix, rf, bounds):
    n = len(mean_returns)
    cons = ({'type': 'eq', 'fun': lambda x: np.sum(x)-1})
    def neg_sharpe(w):
        port_ret = np.dot(w, mean_returns)
        port_vol = np.sqrt(np.dot(w.T, np.dot(cov_matrix, w)))
        return -((port_ret - rf) / port_vol) if port_vol != 0 else 0
    init_guess = np.ones(n)/n
    result = sco.minimize(
        neg_sharpe,
        init_guess,
        method='SLSQP',
        bounds=bounds,
        constraints=cons
    )
    return result.x if result.success else None

def equally_weighted_weights(n):
    return np.ones(n) / n

def portfolio_stats(weights, mean_returns, cov_matrix, returns, rf, annual_factor):
    mean_m = mean_returns / annual_factor
    cov_m = cov_matrix / annual_factor

    port_ann_return = np.dot(weights, mean_returns)
    port_ann_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
    downrets = returns.copy(); downrets[downrets > 0] = 0
    port_ann_downstd = np.sqrt(np.dot(weights.T, np.dot(downrets.cov()*annual_factor, weights)))
    sharpe = (port_ann_return - rf/100) / (port_ann_vol if port_ann_vol else np.nan)
    sortino = (port_ann_return - rf/100) / (port_ann_downstd if port_ann_downstd else np.nan)

    stats = {}
    for label, period in [('Ø³Ø§Ù„Ø§Ù†Ù‡', annual_factor), ('Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡', 3), ('Ø¯ÙˆÙ…Ø§Ù‡Ù‡', 2), ('ÛŒÚ©â€ŒÙ…Ø§Ù‡Ù‡', 1)]:
        mu = np.dot(weights, mean_m)
        sigma = np.sqrt(np.dot(weights, np.dot(cov_m, weights)))
        port_return = mu * period
        port_vol = sigma * np.sqrt(period)
        stats[label] = {"return": port_return, "vol": port_vol}
    stats['sharpe'] = sharpe; stats['sortino'] = sortino
    return stats

# ---------------- Streamlit App -----------------
st.set_page_config(page_title="ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ø³Ø¨Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù", layout="wide")
st.sidebar.markdown("## ğŸ§  ØªØ³Øª Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø±ÛŒØ³Ú© Ø±ÙØªØ§Ø±ÛŒ")
with st.sidebar.expander("Ø§Ù†Ø¬Ø§Ù… ØªØ³Øª Ø±ÛŒØ³Ú© Ø±ÙØªØ§Ø±ÛŒ", expanded=True):
    q1 = st.radio("Ø§Ú¯Ø± Ø§Ø±Ø²Ø´ Ù¾Ø±ØªÙÙˆ Ø´Ù…Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ù…ÙˆÙ‚Øª Û±ÛµÙª Ú©Ø§Ù‡Ø´ ÛŒØ§Ø¨Ø¯ØŒ Ú†Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ØŸ", ["Ø³Ø±ÛŒØ¹ Ù…ÛŒâ€ŒÙØ±ÙˆØ´Ù…", "Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±Ù…", "Ø®Ø±ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ù…"], key="risk_q1")
    q2 = st.radio("Ø¯Ø± ÛŒÚ© Ø³Ø±Ù…Ø§ÛŒÙ‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ù¾Ø±Ø±ÛŒØ³Ú© Ø¨Ø§ Ø¨Ø§Ø²Ø¯Ù‡ Ø¨Ø§Ù„Ø§ØŒ Ú†Ù‡ Ø§Ø­Ø³Ø§Ø³ÛŒ Ø¯Ø§Ø±ÛŒØ¯ØŸ", ["Ù†Ú¯Ø±Ø§Ù†", "Ø¨ÛŒâ€ŒØªÙØ§ÙˆØª", "Ù‡ÛŒØ¬Ø§Ù†â€ŒØ²Ø¯Ù‡"], key="risk_q2")
    q3 = st.radio("Ú©Ø¯Ø§Ù… Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ Ø´Ù…Ø§ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ± Ø§Ø³ØªØŸ", [
        "ØªØ±Ø¬ÛŒØ­ Ù…ÛŒâ€ŒØ¯Ù‡Ù… Ø³ÙˆØ¯ Ú©Ù… ÙˆÙ„ÛŒ Ù‚Ø·Ø¹ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù…",
        "Ø³ÙˆØ¯ Ù…ØªÙˆØ³Ø· ÙˆÙ„ÛŒ Ø¨Ø§ Ú©Ù…ÛŒ Ø±ÛŒØ³Ú© Ø±Ø§ Ù…ÛŒâ€ŒÙ¾Ø°ÛŒØ±Ù…",
        "Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø³ÙˆØ¯ Ø¨Ø§Ù„Ø§ Ù…Ù‡Ù…â€ŒØªØ± Ø§Ø² Ø±ÛŒØ³Ú© Ø§Ø³Øª"
    ], key="risk_q3")
    q4 = st.radio("Ø¯Ø± Ú¯Ø°Ø´ØªÙ‡ Ø§Ú¯Ø± Ø¶Ø±Ø± Ù‚Ø§Ø¨Ù„ ØªÙˆØ¬Ù‡ÛŒ Ú©Ø±Ø¯ÛŒØ¯ØŒ Ú†Ù‡ ÙˆØ§Ú©Ù†Ø´ÛŒ Ø¯Ø§Ø´ØªÛŒØ¯ØŸ", [
        "Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¹Ù‚Ø¨ Ù†Ø´ÛŒÙ†ÛŒ Ú©Ø±Ø¯Ù…",
        "ØªØ­Ù…Ù„ Ú©Ø±Ø¯Ù… Ùˆ ØµØ¨Ø± Ú©Ø±Ø¯Ù…",
        "Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù…"
    ], key="risk_q4")
    q1_map = {"Ø³Ø±ÛŒØ¹ Ù…ÛŒâ€ŒÙØ±ÙˆØ´Ù…": 1, "Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±Ù…": 2, "Ø®Ø±ÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ù…": 3}
    q2_map = {"Ù†Ú¯Ø±Ø§Ù†": 1, "Ø¨ÛŒâ€ŒØªÙØ§ÙˆØª": 2, "Ù‡ÛŒØ¬Ø§Ù†â€ŒØ²Ø¯Ù‡": 3}
    q3_map = {
        "ØªØ±Ø¬ÛŒØ­ Ù…ÛŒâ€ŒØ¯Ù‡Ù… Ø³ÙˆØ¯ Ú©Ù… ÙˆÙ„ÛŒ Ù‚Ø·Ø¹ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù…": 1,
        "Ø³ÙˆØ¯ Ù…ØªÙˆØ³Ø· ÙˆÙ„ÛŒ Ø¨Ø§ Ú©Ù…ÛŒ Ø±ÛŒØ³Ú© Ø±Ø§ Ù…ÛŒâ€ŒÙ¾Ø°ÛŒØ±Ù…": 2,
        "Ù¾ØªØ§Ù†Ø³ÛŒÙ„ Ø³ÙˆØ¯ Ø¨Ø§Ù„Ø§ Ù…Ù‡Ù…â€ŒØªØ± Ø§Ø² Ø±ÛŒØ³Ú© Ø§Ø³Øª": 3
    }
    q4_map = {
        "Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¹Ù‚Ø¨ Ù†Ø´ÛŒÙ†ÛŒ Ú©Ø±Ø¯Ù…": 1,
        "ØªØ­Ù…Ù„ Ú©Ø±Ø¯Ù… Ùˆ ØµØ¨Ø± Ú©Ø±Ø¯Ù…": 2,
        "Ø¨Ø§ ØªØ­Ù„ÛŒÙ„ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù…": 3
    }
    if st.button("Ø«Ø¨Øª Ù†ØªÛŒØ¬Ù‡ ØªØ³Øª Ø±ÛŒØ³Ú© Ø±ÙØªØ§Ø±ÛŒ", key="submit_risk_test"):
        risk_score = q1_map[q1] + q2_map[q2] + q3_map[q3] + q4_map[q4]
        if risk_score <= 6:
            risk_profile = "Ù…Ø­Ø§ÙØ¸Ù‡â€ŒÚ©Ø§Ø± (Conservative)"
            risk_value = 0.10
        elif risk_score <= 9:
            risk_profile = "Ù…ØªØ¹Ø§Ø¯Ù„ (Moderate)"
            risk_value = 0.25
        else:
            risk_profile = "ØªÙ‡Ø§Ø¬Ù…ÛŒ (Aggressive)"
            risk_value = 0.40
        msg(f"Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ø±ÛŒØ³Ú© Ø´Ù…Ø§: **{risk_profile}**", 'success')
        st.session_state["risk_profile"] = risk_profile
        st.session_state["risk_value"] = risk_value

if "risk_profile" not in st.session_state or "risk_value" not in st.session_state:
    st.warning("âš ï¸ ØªØ³Øª Ø±ÛŒØ³Ú© Ø±Ø§ Ú©Ø§Ù…Ù„ Ú©Ù†ÛŒØ¯.")
    st.stop()

st.title("ğŸ“Š Ø§Ø¨Ø²Ø§Ø± ØªØ­Ù„ÛŒÙ„ Ù¾Ø±ØªÙÙˆ Ø¨Ø§ Ø³Ø¨Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù")
with st.sidebar.expander("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ù„ÛŒ", expanded=True):
    period = st.selectbox("Ø¨Ø§Ø²Ù‡ ØªØ­Ù„ÛŒÙ„ Ø¨Ø§Ø²Ø¯Ù‡", ['Ù…Ø§Ù‡Ø§Ù†Ù‡', 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡', 'Ø´Ø´â€ŒÙ…Ø§Ù‡Ù‡'])
    rf = st.number_input("Ù†Ø±Ø® Ø¨Ø¯ÙˆÙ† Ø±ÛŒØ³Ú© Ø³Ø§Ù„Ø§Ù†Ù‡ (%)", min_value=0.0, max_value=100.0, value=3.0, step=0.1)
    st.markdown("---")
    st.markdown("#### :money_with_wings: Ø³Ø±Ù…Ø§ÛŒÙ‡ Ú©Ù„ (Ø¯Ù„Ø§Ø±)")
    total_capital = st.number_input("Ø³Ø±Ù…Ø§ÛŒÙ‡ Ú©Ù„ (Ø¯Ù„Ø§Ø±)", min_value=0.0, value=100000.0, step=100.0)
    st.markdown("#### Ù…Ø¨Ù„Øº Ø¯Ù„Ø§Ø±ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¨Ø§Ø²Ø¯Ù‡ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)")
    capital_for_gain = st.number_input("Ø³Ø±Ù…Ø§ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø§Ø²Ø¯Ù‡ ($)", min_value=0.0, value=total_capital, step=100.0)
    st.markdown("#### ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø±ØªÙÙˆÙ‡Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ")
    n_portfolios = st.slider("ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø±ØªÙÙˆ Ø¨Ø±Ø§ÛŒ Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ", 500, 30000, 7500, 500)
    st.markdown("#### ØªØ¹Ø¯Ø§Ø¯ Ø³ÛŒÙ…ÙˆÙ„ÛŒØ´Ù† Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ")
    n_mc = st.slider("ØªØ¹Ø¯Ø§Ø¯ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø± MC", 250, 4000, 800, 100)
    seed_value = st.number_input("Ø«Ø§Ø¨Øª ØªØµØ§Ø¯ÙÛŒ (seed)", 0, 99999, 42)

with st.sidebar.expander("Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ÙˆØ²Ù† Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ :lock:", expanded=True):
    st.markdown("##### Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ÙˆØ²Ù† Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ")
    uploaded_files = st.file_uploader("Ú†Ù†Ø¯ ÙØ§ÛŒÙ„ CSV Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ (Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ ÛŒÚ© ÙØ§ÛŒÙ„)", type=['csv'], accept_multiple_files=True, key="uploader")
    all_assets = []
    asset_read_errors = []
    if uploaded_files:
        for file in uploaded_files:
            df, err = read_csv_file(file)
            if df is not None:
                all_assets.append((file.name.split('.')[0], df))
            else:
                asset_read_errors.append(f"{file.name}: {err}")
    if "downloaded_dfs" not in st.session_state:
        st.session_state["downloaded_dfs"] = []
    with st.expander("Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ† ğŸ“¥"):
        st.markdown("""
        <div dir="rtl" style="text-align: right;">
        <b>Ø±Ø§Ù‡Ù†Ù…Ø§:</b>
        <br>Ù†Ù…Ø§Ø¯Ù‡Ø§ Ø±Ø§ Ø¨Ø§ Ú©Ø§Ù…Ø§ Ùˆ Ø¨Ø¯ÙˆÙ† ÙØ§ØµÙ„Ù‡ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ (Ù…Ø«Ø§Ù„: <span style="direction:ltr;display:inline-block">BTC-USD,AAPL,ETH-USD</span>)
        </div>
        """, unsafe_allow_html=True)
        tickers_input = st.text_input("Ù†Ù…Ø§Ø¯ Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§")
        start = st.date_input("ØªØ§Ø±ÛŒØ® Ø´Ø±ÙˆØ¹", value=pd.to_datetime("2023-01-01"))
        end = st.date_input("ØªØ§Ø±ÛŒØ® Ù¾Ø§ÛŒØ§Ù†", value=pd.to_datetime("today"))
        download_btn = st.button("Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡")
    if download_btn and tickers_input.strip():
        tickers = [t.strip() for t in tickers_input.strip().split(",") if t.strip()]
        try:
            data = yf.download(tickers, start=start, end=end, progress=False, group_by='ticker', auto_adjust=True)
            if data.empty:
                msg("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯!", "error")
            else:
                new_downloaded = []
                for t in tickers:
                    df, err = get_price_dataframe_from_yf(data, t)
                    if df is not None and not df.empty and not df["Price"].isna().all():
                        df['Date'] = pd.to_datetime(df['Date'])
                        new_downloaded.append((t, df))
                        msg(f"Ø¯Ø§Ø¯Ù‡ {t} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯.", "success")
                    else:
                        asset_read_errors.append(f"{t}: Ø¯Ø§Ø¯Ù‡ Ø¯Ø±ÛŒØ§ÙØªÛŒ Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª ÛŒØ§ Ù¾Ø± Ø§Ø² NaN Ø§Ø³Øª.")
                st.session_state["downloaded_dfs"].extend(new_downloaded)
        except Exception as ex:
            msg(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡: {ex}", "error")
    if st.session_state.get("downloaded_dfs"):
        all_assets.extend(st.session_state["downloaded_dfs"])

    for err in asset_read_errors:
        msg(f"âš ï¸ {err}", "warning")

    asset_min_weights = {}
    asset_max_weights = {}
    asset_names_show = [name for name, df in all_assets if df is not None]
    for name, df in all_assets:
        if df is None: continue
        asset_min_weights[name] = st.number_input(
            f"Ø­Ø¯Ø§Ù‚Ù„ ÙˆØ²Ù† {name}", min_value=0.0, max_value=100.0, value=0.0, step=1.0, key=f"min_weight_{name}"
        )
        asset_max_weights[name] = st.number_input(
            f"Ø­Ø¯Ø§Ú©Ø«Ø± ÙˆØ²Ù† {name}", min_value=0.0, max_value=100.0, value=100.0, step=1.0, key=f"max_weight_{name}"
        )
    if len(all_assets) > 0:
        is_valid, weights_msg = validate_weights(asset_min_weights, asset_max_weights, asset_names_show)
        if not is_valid:
            st.warning(weights_msg)

resample_rule = {'Ù…Ø§Ù‡Ø§Ù†Ù‡': 'M', 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡': 'Q', 'Ø´Ø´â€ŒÙ…Ø§Ù‡Ù‡': '2Q'}[period]
annual_factor = {'Ù…Ø§Ù‡Ø§Ù†Ù‡': 12, 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡': 4, 'Ø´Ø´â€ŒÙ…Ø§Ù‡Ù‡': 2}[period]
user_risk = st.sidebar.slider("Ø±ÛŒØ³Ú© Ù‡Ø¯Ù Ù¾Ø±ØªÙÙˆ (Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÛŒØ§Ø± Ø³Ø§Ù„Ø§Ù†Ù‡)", 0.01, 1.0, float(st.session_state.get("risk_value", 0.25)), 0.01)
cvar_alpha = st.sidebar.slider("Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† CVaR", 0.80, 0.99, 0.95, 0.01)

if is_all_assets_valid(all_assets):
    prices_df = pd.DataFrame()
    for name, df in all_assets:
        if df is None or 'Date' not in df.columns or 'Price' not in df.columns:
            continue
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        df['Price'] = df['Price'].astype(str).str.replace(',', '')
        df['Price'] = pd.to_numeric(df['Price'], errors='coerce')
        df = df.dropna(subset=['Date', 'Price'])
        df = df[['Date', 'Price']].set_index('Date')
        df.columns = [name]
        prices_df = df if prices_df.empty else prices_df.join(df, how='inner')
    asset_names = list(prices_df.columns)
    if prices_df.empty or len(asset_names) == 0:
        st.error("âŒ Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯ - Ù„Ø·ÙØ§Ù‹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯.")
        st.stop()
    st.subheader("ğŸ§ª Ù¾ÛŒØ´â€ŒÙ†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
    st.dataframe(prices_df.tail())

    insured_assets = {}
    for name in asset_names:
        st.sidebar.markdown(f"---\n### âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨ÛŒÙ…Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø±Ø§ÛŒÛŒ: `{name}`")
        insured = st.sidebar.checkbox(f"ğŸ“Œ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨ÛŒÙ…Ù‡ Ø¨Ø±Ø§ÛŒ {name}", key=f"insured_{name}")
        if insured:
            loss_percent = st.sidebar.number_input(f"ğŸ“‰ Ø¯Ø±ØµØ¯ Ø¶Ø±Ø± Ù…Ø¹Ø§Ù…Ù„Ù‡ Ù¾ÙˆØª Ø¨Ø±Ø§ÛŒ {name}", 0.0, 100.0, 30.0, step=0.01, key=f"loss_{name}")
            strike = st.sidebar.number_input(f"ğŸ¯ Ù‚ÛŒÙ…Øª Ø§Ø¹Ù…Ø§Ù„ Ù¾ÙˆØª Ø¨Ø±Ø§ÛŒ {name}", 0.0, 1e6, 100.0, step=0.01, key=f"strike_{name}")
            premium = st.sidebar.number_input(f"ğŸ’° Ù‚ÛŒÙ…Øª Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ù¾ÙˆØª Ø¨Ø±Ø§ÛŒ {name}", 0.0, 1e6, 5.0, step=0.01, key=f"premium_{name}")
            amount = st.sidebar.number_input(f"ğŸ“¦ Ù…Ù‚Ø¯Ø§Ø± Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯ Ø¨Ø±Ø§ÛŒ {name}", 0.0, 1e6, 1.0, step=0.01, key=f"amount_{name}")
            spot_price = st.sidebar.number_input(f"ğŸ“Œ Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ø¯Ø§Ø±Ø§ÛŒÛŒ Ù¾Ø§ÛŒÙ‡ {name}", 0.0, 1e6, 100.0, step=0.01, key=f"spot_{name}")
            asset_amount = st.sidebar.number_input(f"ğŸ“¦ Ù…Ù‚Ø¯Ø§Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ Ù¾Ø§ÛŒÙ‡ {name}", 0.0, 1e6, 1.0, step=0.01, key=f"base_{name}")
            insured_assets[name] = {
                'loss_percent': loss_percent,
                'strike': strike,
                'premium': premium,
                'amount': amount,
                'spot': spot_price,
                'base': asset_amount
            }

    resampled_prices = prices_df.resample(resample_rule).last().dropna()
    returns = resampled_prices.pct_change().dropna()
    mean_returns = returns.mean() * annual_factor
    cov_matrix = returns.cov() * annual_factor
    std_devs = np.sqrt(np.diag(cov_matrix))

    adjusted_cov = cov_matrix.copy()
    preference_weights = []
    for i, name in enumerate(asset_names):
        if name in insured_assets:
            risk_scale = 1 - insured_assets[name]['loss_percent'] / 100
            adjusted_cov.iloc[i, :] *= risk_scale
            adjusted_cov.iloc[:, i] *= risk_scale
            preference_weights.append(1 / max(std_devs[i] * risk_scale**0.7, 1e-4))
        else:
            preference_weights.append(1 / max(std_devs[i], 1e-4))
    preference_weights = np.array(preference_weights)
    preference_weights /= np.sum(preference_weights)

    np.random.seed(seed_value)
    results = np.zeros((5 + len(asset_names), n_portfolios))
    downside = returns.copy(); downside[downside > 0] = 0

    min_weights_arr = np.array([asset_min_weights.get(name, 0)/100 for name in asset_names])
    max_weights_arr = np.array([asset_max_weights.get(name, 100)/100 for name in asset_names])
    valid_minmax, _ = validate_weights(asset_min_weights, asset_max_weights, asset_names)
    if not valid_minmax:
        st.error("Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ ÙˆØ²Ù† Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ Ø§Ø´ØªØ¨Ø§Ù‡ ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        st.stop()

    for i in range(n_portfolios):
        weights = np.random.random(len(asset_names)) * preference_weights
        weights /= np.sum(weights)
        weights = min_weights_arr + (max_weights_arr - min_weights_arr) * weights
        weights /= np.sum(weights)
        if np.sum(min_weights_arr) > 1:
            weights = min_weights_arr / np.sum(min_weights_arr)
        port_return = np.dot(weights, mean_returns)
        port_std = np.sqrt(np.dot(weights.T, np.dot(adjusted_cov, weights)))
        downside_risk = np.sqrt(np.dot(weights.T, np.dot(downside.cov() * annual_factor, weights)))
        sharpe_ratio = (port_return - rf/100) / (port_std if port_std!=0 else np.nan)
        sortino_ratio = (port_return - rf/100) / (downside_risk if downside_risk>0 else np.nan)

        mc_sims = np.random.multivariate_normal(mean_returns/annual_factor, adjusted_cov/annual_factor, n_mc)
        port_mc_returns = np.dot(mc_sims, weights)
        VaR = np.percentile(port_mc_returns, (1 - cvar_alpha) * 100)
        CVaR = port_mc_returns[port_mc_returns <= VaR].mean() if np.any(port_mc_returns <= VaR) else VaR

        results[0, i] = port_return
        results[1, i] = port_std
        results[2, i] = sharpe_ratio
        results[3, i] = sortino_ratio
        results[4, i] = -CVaR
        results[5:, i] = weights

    # Ø³Ø¨Ú©â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ØªÙÙˆ Ùˆ Ø¢Ù…Ø§Ø± Ø¢Ù†Ù‡Ø§
    best_idx = np.argmin(np.abs(results[1] - user_risk))
    best_weights = results[5:, best_idx]
    cvar_idx = np.nanargmin(results[4])
    cvar_weights = results[5:, cvar_idx]
    bounds = [(asset_min_weights.get(name,0)/100, asset_max_weights.get(name,100)/100) for name in asset_names]
    w_mvp = opt_min_variance(mean_returns, cov_matrix, bounds)
    w_sharpe = opt_max_sharpe(mean_returns, cov_matrix, rf/100, bounds)
    w_eq = equally_weighted_weights(len(asset_names))

    style_dict = {
        'Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ': best_weights,
        f'CVaR {int(cvar_alpha*100)}%': cvar_weights,
        'Ù…ÛŒÙ†ÛŒÙ…Ù… ÙˆØ§Ø±ÛŒØ§Ù†Ø³': w_mvp if w_mvp is not None else np.zeros(len(asset_names)),
        'Ù…Ø§Ú©Ø²ÛŒÙ…Ù… Ø´Ø§Ø±Ù¾': w_sharpe if w_sharpe is not None else np.zeros(len(asset_names)),
        'ÙˆØ²Ù† Ø¨Ø±Ø§Ø¨Ø±': w_eq
    }
    style_keys = list(style_dict.keys())
    color_map = {
        'Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ': '#03a678',
        f'CVaR {int(cvar_alpha*100)}%': '#d35400',
        'Ù…ÛŒÙ†ÛŒÙ…Ù… ÙˆØ§Ø±ÛŒØ§Ù†Ø³': '#8e44ad',
        'Ù…Ø§Ú©Ø²ÛŒÙ…Ù… Ø´Ø§Ø±Ù¾': '#34495e',
        'ÙˆØ²Ù† Ø¨Ø±Ø§Ø¨Ø±': "#7ed6a5"
    }
    min_percent_for_pie = 0.1

    # Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ùˆ pie Ù‡Ø± Ø³Ø¨Ú© + Ø³ÙˆØ¯ Ø¯Ù„Ø§Ø±ÛŒ Ù‡Ø± Ø³Ø¨Ú© Ùˆ Ù‡Ø± Ø¨Ø§Ø²Ù‡
    st.subheader(":rocket: Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ø¨Ø¯ Ùˆ Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø§ÛŒØ±Ù‡â€ŒØ§ÛŒ Ø³Ø¨Ú©â€ŒÙ‡Ø§")
    gains_table = {}
    periods = [('Ø³Ø§Ù„Ø§Ù†Ù‡', 1), ('Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡', 3/12), ('Ø¯ÙˆÙ…Ø§Ù‡Ù‡', 2/12), ('ÛŒÚ©â€ŒÙ…Ø§Ù‡Ù‡', 1/12)]
    for style, weights in style_dict.items():
        stats = portfolio_stats(weights, mean_returns, cov_matrix, returns, rf, annual_factor)
        shown_names, shown_weights = compact_pie_weights(asset_names, weights, min_percent=min_percent_for_pie)
        fig_pie = px.pie(
            names=shown_names,
            values=shown_weights,
            title=f"ØªÙˆØ²ÛŒØ¹ ÙˆØ²Ù†ÛŒ Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§ ({style})",
            hole=0.3,
            color=shown_names,
            color_discrete_sequence=px.colors.qualitative.Pastel
        )
        fig_pie.update_traces(textinfo='percent+label+value',
                              pull=[0.08 if n in insured_assets else 0 for n in shown_names],
                              marker=dict(line=dict(color='#222', width=2)))
        fig_pie.update_layout(font_family="Vazirmatn", title_font_size=20, height=340)
        st.plotly_chart(fig_pie, use_container_width=True)

        st.markdown(f"##### <span style='color:{color_map[style]}'>Ø³Ø¨Ú©: {style}</span>", unsafe_allow_html=True)
        gain_row = []
        for (p_label, p_mult) in periods:
            exp_ret = stats[p_label]['return']
            exp_gain = exp_ret * capital_for_gain
            gain_row.append(exp_gain)
            st.write(f"ğŸ“ˆ Ø³ÙˆØ¯ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± {p_label}: **{exp_gain:,.0f} $**  (Ø³ÙˆØ¯ Ù†Ø³Ø¨ÛŒ: {exp_ret*100:.2f}%)")
            st.write(f"âš ï¸ Ø±ÛŒØ³Ú©/Ù†ÙˆØ³Ø§Ù† {p_label}: **{stats[p_label]['vol']*100:.2f}%**")
            if p_label == 'Ø³Ø§Ù„Ø§Ù†Ù‡':
                st.write(f"ğŸ”¹ Ù†Ø³Ø¨Øª Ø´Ø§Ø±Ù¾: {stats['sharpe']:.2f} | Ù†Ø³Ø¨Øª Ø³ÙˆØ±ØªÛŒÙ†Ùˆ: {stats['sortino']:.2f}")
        gains_table[style] = gain_row
        st.markdown("---")

    # Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø³ÙˆØ¯ Ø¯Ù„Ø§Ø±ÛŒ Ø³Ø¨Ú©â€ŒÙ‡Ø§
    col_gains = ['Ø³Ø§Ù„Ø§Ù†Ù‡', 'Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡', 'Ø¯ÙˆÙ…Ø§Ù‡Ù‡', 'ÛŒÚ©â€ŒÙ…Ø§Ù‡Ù‡']
    st.subheader("ğŸ“‹ Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø³ÙˆØ¯ Ø¯Ù„Ø§Ø±ÛŒ Ø³Ø¨Ú©â€ŒÙ‡Ø§")
    gains_df = pd.DataFrame(gains_table, index=col_gains)
    st.dataframe(gains_df.T, use_container_width=True)

    # Ù†Ù…ÙˆØ¯Ø§Ø± Ù…ÛŒÙ„Ù‡â€ŒØ§ÛŒ Ø³ÙˆØ¯ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¨Ø§Ø²Ù‡ (Ù‡Ø± Ù†Ù…ÙˆØ¯Ø§Ø± ÛŒÚ© Ø¨Ø§Ø²Ù‡Ø› Ø³Ø¨Ú©â€ŒÙ‡Ø§ Ú©Ù†Ø§Ø± Ù‡Ù…)
    st.subheader("ğŸ“ˆ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ù„Ø§Ø±ÛŒ Ø³Ø¨Ú©â€ŒÙ‡Ø§ Ø¯Ø± Ù‡Ø± Ø¨Ø§Ø²Ù‡ (Bar Chart)")
    for i, period in enumerate(col_gains):
        fig_bar = go.Figure()
        for style in style_keys:
            fig_bar.add_trace(go.Bar(
                x=[style], y=[gains_df[style][i]], name=style, marker_color=color_map[style]
            ))
        # Ø³ØªÙˆÙ†ÛŒ:
        fig_bar.update_layout(
            title=f"Ø³ÙˆØ¯ Ø¯Ù„Ø§Ø±ÛŒ {period} (Ø¨Ø±Ø§ÛŒ Ø³Ø±Ù…Ø§ÛŒÙ‡ {capital_for_gain:,.0f} Ø¯Ù„Ø§Ø±)",
            yaxis_title="Ø³ÙˆØ¯ ØªØ®Ù…ÛŒÙ†ÛŒ ($)",
            showlegend=False,
            font_family="Vazirmatn",
            title_font_size=22
        )
        st.plotly_chart(fig_bar, use_container_width=True)

    # Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø³Ø¨Ú©â€ŒÙ‡Ø§
    st.subheader("ğŸ“‹ Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡ ÙˆØ²Ù† Ø¯Ø§Ø±Ø§ÛŒÛŒâ€ŒÙ‡Ø§")
    compare_dict = {"Ø¯Ø§Ø±Ø§ÛŒÛŒ": asset_names}
    for style, weights in style_dict.items():
        compare_dict[style] = [w*100 for w in weights]
    df_compare = pd.DataFrame(compare_dict)
    st.dataframe(df_compare.set_index("Ø¯Ø§Ø±Ø§ÛŒÛŒ"), use_container_width=True)

    # Ù…Ø±Ø² Ú©Ø§Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø³Ø¨Ú©: ÙÙ‚Ø· Ø¬Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ø¹Ù†ÛŒâ€ŒØ¯Ø§Ø± Ø§Ø³Øª (Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ Ùˆ CVaRØŒ Ùˆ Ø³Ø¨Ú©â€ŒÙ‡Ø§ÛŒ Ù†Ù‚Ø·Ù‡â€ŒØ§ÛŒ)
    st.subheader("ğŸŒˆ Ù…Ø±Ø² Ú©Ø§Ø±Ø§ Ù¾Ø±ØªÙÙˆÙ‡Ø§ (Ø³Ø¨Ú©â€ŒÙ‡Ø§)")
    for style in style_keys:
        st.markdown(f"#### Ù…Ø±Ø² Ú©Ø§Ø±Ø§: {style}")
        if style in ['Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ', f'CVaR {int(cvar_alpha*100)}%']:
            idx = best_idx if style == 'Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ' else cvar_idx
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=results[1]*100, y=results[0]*100,
                mode='markers', marker=dict(
                    size=6, color=results[2] if style == 'Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ' else -results[4],
                    colorscale='Viridis' if style == 'Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ' else 'Blues',
                    colorbar=dict(title='Sharpe' if style=='Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ' else '-CVaR')
                ),
                name="Ù¾Ø±ØªÙÙˆÙ‡Ø§ÛŒ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒâ€ŒØ´Ø¯Ù‡"
            ))
            w = (best_weights if style=='Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ' else cvar_weights)
            fig.add_trace(go.Scatter(
                x=[np.sqrt(np.dot(w.T, np.dot(cov_matrix, w)))*100],
                y=[np.dot(w, mean_returns)*100], mode='markers+text',
                marker=dict(size=18, color='red' if style=='Ù…ÙˆÙ†Øªâ€ŒÚ©Ø§Ø±Ù„Ùˆ' else 'orange', symbol='star'),
                name=f"Ø¨Ù‡ÛŒÙ†Ù‡ {style}", text=["â­"], textposition="top center"
            ))
            fig.update_layout(
                title=f"Ù…Ø±Ø² Ú©Ø§Ø±Ø§ - {style}",
                xaxis_title="Ø±ÛŒØ³Ú© Ø³Ø§Ù„Ø§Ù†Ù‡ (%)", yaxis_title="Ø¨Ø§Ø²Ø¯Ù‡ Ø³Ø§Ù„Ø§Ù†Ù‡ (%)",
                font_family="Vazirmatn", title_font_size=22
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            # Ù…ÛŒÙ†ÛŒÙ…Ù… ÙˆØ§Ø±ÛŒØ§Ù†Ø³ - Ù…Ø§Ú©Ø²ÛŒÙ…Ù… Ø´Ø§Ø±Ù¾ - ÙˆØ²Ù† Ø¨Ø±Ø§Ø¨Ø±ØŒ Ù†Ù‚Ø·Ù‡â€ŒØ§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø¯Ù‡
            w = style_dict[style]
            port_return = np.dot(w, mean_returns)
            port_vol = np.sqrt(np.dot(w.T, np.dot(cov_matrix, w)))
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=[port_vol*100], y=[port_return*100],
                mode='markers+text',
                marker=dict(size=18, color=color_map[style], symbol='star'),
                name=f'Ø¨Ù‡ÛŒÙ†Ù‡ {style}',
                text=["â­"], textposition="top center"
            ))
            fig.update_layout(
                title=f"Ù…Ø±Ø² Ú©Ø§Ø±Ø§ - {style}",
                xaxis_title="Ø±ÛŒØ³Ú© Ø³Ø§Ù„Ø§Ù†Ù‡ (%)", yaxis_title="Ø¨Ø§Ø²Ø¯Ù‡ Ø³Ø§Ù„Ø§Ù†Ù‡ (%)",
                font_family="Vazirmatn", title_font_size=22
            )
            st.plotly_chart(fig, use_container_width=True)

    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª Ø¨Ø±Ø§ÛŒ 3/2/1 Ù…Ø§Ù‡Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ
    st.subheader("ğŸ”® Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª Ùˆ Ø¨Ø§Ø²Ø¯Ù‡ Ø¢ØªÛŒ Ù‡Ø± Ø¯Ø§Ø±Ø§ÛŒÛŒ")
    prediction_periods = [("Ø³Ù‡â€ŒÙ…Ø§Ù‡Ù‡ (Û³ Ù…Ø§Ù‡)", 3), ("Ø¯Ùˆ Ù…Ø§Ù‡Ù‡", 2), ("ÛŒÚ© Ù…Ø§Ù‡Ù‡", 1)]
    for i, name in enumerate(asset_names):
        last_price = resampled_prices[name].iloc[-1]
        mu = mean_returns[i] / annual_factor
        sigma = std_devs[i] / np.sqrt(annual_factor)
        if sigma < 1e-4:
            st.info(f"Ø¨Ø±Ø§ÛŒ {name} ÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø³ÛŒØ§Ø± Ú©Ù… Ø§Ø³Øª Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¹Ù†Ø§Ø¯Ø§Ø±ÛŒ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ø§Ø¯.")
            continue
        st.markdown(f"#### {name}")
        cols = st.columns(len(prediction_periods))
        for j, (label, future_months) in enumerate(prediction_periods):
            sim_prices = []
            n_sim = 500
            for _ in range(n_sim):
                sim = last_price * np.exp(np.cumsum(np.random.normal(mu, sigma, future_months)))
                sim_prices.append(sim[-1])
            sim_prices = np.array(sim_prices)
            future_price_mean = np.mean(sim_prices)
            future_return = (future_price_mean - last_price) / last_price
            with cols[j]:
                fig_pred = go.Figure()
                fig_pred.add_trace(go.Histogram(x=sim_prices, nbinsx=20, name="Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù‚ÛŒÙ…Øª", marker_color='purple'))
                fig_pred.add_vline(x=future_price_mean, line_dash="dash", line_color="green")
                fig_pred.update_layout(
                    title=f"{label}",
                    xaxis_title="Ù‚ÛŒÙ…Øª Ø§Ù†ØªÙ‡Ø§ÛŒÛŒ", 
                    yaxis_title="ØªØ¹Ø¯Ø§Ø¯ Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ", 
                    font_family="Vazirmatn", 
                    title_font_size=16,
                    height=270
                )
                st.plotly_chart(fig_pred, use_container_width=True)
                st.markdown(f"ğŸ“ˆ **Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†:** `{future_price_mean:.2f}`")
                st.markdown(f"ğŸ“Š **Ø¨Ø§Ø²Ø¯Ù‡:** `{future_return:.2%}`")
        st.markdown("---")

else:
    st.warning("âš ï¸ Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ CSV Ù…Ø¹ØªØ¨Ø± Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Date Ùˆ Price Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ ÛŒØ§ Ø¯Ø§Ø¯Ù‡ Ø¢Ù†Ù„Ø§ÛŒÙ† ÙˆØ§Ø±Ø¯ Ù†Ù…Ø§ÛŒÛŒØ¯.")